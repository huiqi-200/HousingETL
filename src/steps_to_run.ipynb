{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5bb3b3f",
   "metadata": {},
   "source": [
    "## Running the full ETL pipeline\n",
    "\n",
    "Below are the concise steps a data analyst should follow to perform data-quality checks and then transform the cleaned data.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082f3879",
   "metadata": {},
   "source": [
    "1. **Prerequisite** – ensure a Python virtual environment is active and the project dependencies are installed: \n",
    "   ```bash\n",
    "   python -m venv .venv\n",
    "   .venv\\\\Scripts\\\\activate      # Windows\n",
    "   pip install -r requirements.txt\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239af7b8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "2. **Data availability** – raw CSV files should reside in `../Raw` relative to the `src` folder; these files come from the HDB resale dataset.  The schema defined in `resale_flat_schema.raw_resale_flat_schema` treats most columns as strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c471e9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "3. **Profile raw data** – execute the first code cell below to load all raw files and generate an HTML profiling report:\n",
    "   *Assumptions:* the dataset contains columns listed in `config.json` and months span from 1990 onward. The profiler helps discover actual values for categorical columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07f14b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_quality_check import data_profiling_run\n",
    "data_profiling_run(reprofile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df483dbf",
   "metadata": {},
   "source": [
    "First run data_quality_run to identify the actual categorical values used for `Town, Flat Type, Flat\n",
    "Model`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915086d1",
   "metadata": {},
   "source": [
    "From the profiling: \n",
    "1. Categorical values used will be the most common values that appear\n",
    "2. Categorical values get split between Upper and lower case. Will add additional step to convert all to UPPER CASE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a565652e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "4. **Update rules** – inspect `data_quality_rules.json` and adjust `expected_values` lists for `flat_type`, `flat_model`, etc.  Rules are applied after upper‑casing to normalize case variations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9112a9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "5. **Run validation** – call `data_validation` from `data_quality_check` to clean the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509fc04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_quality_check import data_validation, combine_datasets\n",
    "from pathlib import Path\n",
    "raw = combine_datasets(Path('../Raw'))\n",
    "qualified, unqualified = data_validation(raw)\n",
    "\n",
    "print(qualified.head(n=50))\n",
    "print(unqualified.head(n=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b813e3",
   "metadata": {},
   "source": [
    "\n",
    "   *Behavior:*\n",
    "   - Rows with missing key fields are removed.\n",
    "   - Only months between Jan 2016 and Jan 2019 are kept (per `filter_month_range`).\n",
    "   - Categorical values are upper‑cased and filtered using the rules.\n",
    "   - Numeric casts and lease calculations are performed.\n",
    "   - Duplicate records based on composite key are split into qualified and failed sets.\n",
    "   - Cleaned rows are written to `../Data/Cleaned.csv`, failed ones to `../Data/Failed.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c30403",
   "metadata": {},
   "source": [
    "6. **Transform cleaned data** – once you have `Cleaned.csv`, run the transformation logic:  \n",
    "   This function\n",
    "   - reads `Cleaned.csv` using the cleaned schema,\n",
    "   - generates `block_num` (3‑digit, zero‑padded numeric part of `block`),\n",
    "   - computes average resale price by month & flat type,\n",
    "   - joins the average back to every row,\n",
    "   - builds a `resale_identifier` with format\n",
    "     `S{block_num}{last2(avg_price)}{month}{town[1:]}`.\n",
    "   - duplicates are detected and failed records exported; cleaned results go to `../Data/Transformed.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8d3f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_transformation import transform_cleaned_data\n",
    "transformed = transform_cleaned_data()\n",
    "\n",
    "print(transformed.head(n=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de24deb0",
   "metadata": {},
   "source": [
    "7. **Review outputs** – inspect the CSV files under `Data` and use the profiling report or additional analysis as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aeacfb",
   "metadata": {},
   "source": [
    "### Notes & assumptions\n",
    "\n",
    "* The `month` field is assumed to be parseable as a date; rows outside the specified range are removed early.\n",
    "* The transformation uses Polars for performance and adds logging at each key step; logs appear on the console and in `housing_etl.log` if `LogsFolderName` is configured.\n",
    "* Adjust the `data_quality_rules.json` and `config.json` as the dataset evolves.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4513e31",
   "metadata": {},
   "source": [
    "## System Design\n",
    "![alt text](System_Design.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80de4e7",
   "metadata": {},
   "source": [
    "### Network considerations:\n",
    "\n",
    "1. AWS athena will be given access to VPC S3 instance\n",
    "2. Tableau will be given IAM with valid credentials for Athena"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d72a468",
   "metadata": {},
   "source": [
    "## Markdown code to generate system diagram: \n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "\n",
    "  %% Public Internet (only for source upload)\n",
    "  subgraph INTERNET [Public Internet]\n",
    "    SOURCE@{ img: \"https://api.iconify.design/mdi/earth.svg\", label: \"Data Gov Site\", pos: \"b\", w: 60, h: 60, constraint: \"on\"}\n",
    "    TABLEAU_A@{ img: \"https://api.iconify.design/logos/tableau-icon.svg\", label: \"Tableau\", pos: \"b\", w: 60, h: 60, constraint: \"on\"}\n",
    "\n",
    "  end\n",
    "\n",
    "  \n",
    "\n",
    "  %% Enterprise VPC (Singapore Region)\n",
    "  subgraph VPC [Enterprise VPC in Singapore]\n",
    "           ATHENA__A@{ img: \"https://api.iconify.design/logos/aws-athena.svg\", label: \"Athena\", pos: \"b\", w: 60, h: 60, constraint: \"on\"}\n",
    "        LAMBDA_A@{ img: \"https://api.iconify.design/logos/aws-lambda.svg\", label: \"AWS Lambda\", pos: \"b\", w: 60, h: 60, constraint: \"on\"}\n",
    "    %% Availability Zone A\n",
    "    subgraph AZ_A [Availability Zone A]\n",
    "      subgraph PRIVATE_SUBNET_A [Private Subnet A]\n",
    "        S3_GW_A@{ img: \"https://api.iconify.design/logos/aws-s3.svg\", label: \"S3 Primary\", pos: \"b\", w: 60, h: 60, constraint: \"on\"}\n",
    "        end\n",
    "    end\n",
    "\n",
    "    %% Availability Zone B\n",
    "    subgraph AZ_B [Availability Zone B]\n",
    "      subgraph PRIVATE_SUBNET_B [Private Subnet B]\n",
    "        S3_GW_B@{ img: \"https://api.iconify.design/logos/aws-s3.svg\", label: \"S3 Secondary\", pos: \"b\", w: 60, h: 60, constraint: \"on\"}\n",
    "      end\n",
    "    end\n",
    "\n",
    "\n",
    "  end\n",
    "\n",
    "  %% Data Flow\n",
    "\n",
    "    S3_GW_A -- \"5. Replication\" --> S3_GW_B\n",
    "\n",
    "\n",
    "  LAMBDA_A -- \"1. Trigger file upload\" --> SOURCE\n",
    "  SOURCE -- \"2. Multipart file Download into\" --> S3_GW_A\n",
    "  LAMBDA_A -- \"3. Runs ETL Pipeline\" --> S3_GW_A\n",
    "  ATHENA__A-- \"4. Query via Proxy \" -->  S3_GW_A\n",
    "  TABLEAU_A -- \"Will access via PrivateLink\" --> ATHENA__A\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  %% Styling\n",
    "  classDef vpc fill:none,color:#0a0,stroke:#0a0,stroke-dasharray: 5 5, stroke-width: 2px\n",
    "  class VPC vpc\n",
    "  class INTERNET,PRIVATE_SUBNET_A,PRIVATE_SUBNET_B,AZ_A,AZ_B,LB_LAYER group\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
